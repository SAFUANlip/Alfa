
# [Кредитный скоринг на данных кредитных историй](https://ods.ai/competitions/dl-fintech-bki/leaderboard)

[Данные](https://disk.yandex.ru/d/K1cxGrw1KDmBsg)

[Метрика](https://alexanderdyakonov.wordpress.com/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/)

Кредитный скоринг – важнейшая банковская задача. Стандартным подходом к ее решению является построение классических моделей машинного обучения, таких как логистическая регрессия и градиентный бустинг, на табличных данных, в том числе используя агрегации от каких-нибудь последовательных данных, например, транзакционных историй клиентов. Альтернативный подход заключается в использовании последовательных данных “как есть”, подавая их на вход рекуррентной нейронной сети.

В этом соревновании участникам предлагается решить задачу кредитного скоринга клиентов Альфа-Банка, используя только данные кредитных историй.

## Эксперимент
Размер сконкатенированного Embedding всех признаков был 175
1) Изначально была взята модель архитектруы GRU, ее результат нужно было превзойти
2) BiLSTM, без конкатенации входа и выхода LSTM, и без регуляризации
3) BiLSTM, без конкатенации входа и выхода LSTM, и с регуляризацией, L1+L2, коэффициенты были взяты 1e-4, 1e-5 соответственно
4) BiLSTM, с конкатенацией входа и выхода LSTM, и с регуляризацией, L1+L2, коэффициенты были взяты 0, 0 соответственно
5) BiLSTM, с конкатенацией входа и выхода LSTM + AdapTiveMaxPooling, начальный Learning Rate 1e-4

## Результаты
Лучшими результатами оказалась последняя модель, чему соответствует значение метрики 0.7656175322.
Также были проведены эксперементы с [DropOut2d](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html) и [lr_scheduler.OneCycleLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR), однако они не дали улучшений.
Возможно основной причиной низкого прироста метрики является размер Embedding 175, ведь в base line эксперименте рамзер Embedding был 258.

## Для воспроизведение лучших результатов
1) Скачайте [архив](https://drive.google.com/file/d/1ZODshhUbFCqeouQ3yu2zuX9lRDrU3UQE/view?usp=sharing) с подготовленными данными
2) Разархивируйте скачанный архив, в папку ```data_MliF```
3) Запустите файл ```train.py``` для обучения модели
4) В папке ```weights/LSTM_weights_1_1_lr-4/``` будут лежать веса обученной модели
5) Запустите файл ```infer.py```
6) В папке ```results``` появится csv файл с предсказаниями 